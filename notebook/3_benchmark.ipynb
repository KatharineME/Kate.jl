{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Main.ProcessSequence"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"../src/ProcessSequence.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/home/jovyan/ProcessSequence.jl/input/high_confidence_HG002_4.1_GRCh38\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_dir = dirname(@__DIR__)\n",
    "\n",
    "using JSON: parse\n",
    "\n",
    "project_json = parse(read(joinpath(project_dir, \"project.json\"), String))\n",
    "\n",
    "sample_name = project_json[\"sample_name\"]\n",
    "\n",
    "output_dir = joinpath(project_dir, \"output\")\n",
    "\n",
    "input_dir = joinpath(project_dir, \"input\")\n",
    "\n",
    "sample_dir = joinpath(input_dir, sample_name)\n",
    "\n",
    "reference_dir = joinpath(input_dir, \"reference\")\n",
    "\n",
    "benchmark_data_dir = joinpath(input_dir, \"high_confidence_HG002_4.1_GRCh38\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "IOError: could not spawn `no`: no such file or directory (ENOENT)",
     "output_type": "error",
     "traceback": [
      "IOError: could not spawn `no`: no such file or directory (ENOENT)",
      "",
      "Stacktrace:",
      " [1] _spawn_primitive(::String, ::Cmd, ::Array{Any,1}) at ./process.jl:99",
      " [2] _spawn(::Cmd, ::Array{Any,1}, ::Base.ProcessChain) at ./process.jl:181",
      " [3] _spawn(::Base.OrCmds, ::Array{Any,1}, ::Base.ProcessChain) at ./process.jl:151",
      " [4] #587 at ./process.jl:120 [inlined]",
      " [5] setup_stdios(::Base.var\"#587#588\"{Base.OrCmds}, ::Array{Any,1}) at ./process.jl:196",
      " [6] _spawn at ./process.jl:119 [inlined]",
      " [7] run(::Base.OrCmds; wait::Bool) at ./process.jl:439",
      " [8] run(::Base.OrCmds) at ./process.jl:438",
      " [9] top-level scope at In[6]:1",
      " [10] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Usage: rtg COMMAND [OPTION]...\n",
      "       rtg RTG_MEM=16G COMMAND [OPTION]...  (e.g. to set maximum memory use to\n",
      "\t             \t16 GB)\n",
      "\n",
      "Type 'rtg help COMMAND' for help on a specific command.\n",
      "The following commands are available:\n",
      "\n",
      "Data formatting:\n",
      "\tformat       \tconvert sequence data files to SDF\n",
      "\tsdf2fasta    \tconvert SDF to FASTA\n",
      "\tsdf2fastq    \tconvert SDF to FASTQ\n",
      "\tsdf2sam      \tconvert SDF to SAM/BAM\n",
      "\tfastqtrim    \ttrim reads in FASTQ files\n",
      "\n",
      "Simulation:\n",
      "\tgenomesim    \tgenerate simulated genome sequence\n",
      "\tcgsim        \tgenerate simulated reads from a sequence\n",
      "\treadsim      \tgenerate simulated reads from a sequence\n",
      "\tpopsim       \tgenerate a VCF containing simulated population variants\n",
      "\tsamplesim    \tgenerate a VCF containing a genotype simulated from a population\n",
      "\tchildsim     \tgenerate a VCF containing a genotype simulated as a child of two\n",
      "\t             \tparents\n",
      "\tdenovosim    \tgenerate a VCF containing a derived genotype containing de novo\n",
      "\t             \tvariants\n",
      "\tpedsamplesim \tgenerate simulated genotypes for all members of a pedigree\n",
      "\tsamplereplay \tgenerate the genome corresponding to a sample genotype\n",
      "\n",
      "Utility:\n",
      "\tbgzip        \tcompress a file using block gzip\n",
      "\tindex        \tcreate a tabix index\n",
      "\textract      \textract data from a tabix indexed file\n",
      "\tsdfstats     \tprint statistics about an SDF\n",
      "\tsdfsubset    \textract a subset of an SDF into a new SDF\n",
      "\tsdfsubseq    \textract a subsequence from an SDF as text\n",
      "\tmendelian    \tcheck a multisample VCF for Mendelian consistency\n",
      "\tvcfstats     \tprint statistics about variants contained within a VCF file\n",
      "\tvcfmerge     \tmerge single-sample VCF files into a single multi-sample VCF\n",
      "\tvcffilter    \tfilter records within a VCF file\n",
      "\tvcfannotate  \tannotate variants within a VCF file\n",
      "\tvcfsubset    \tcreate a VCF file containing a subset of the original columns\n",
      "\tvcfsplit     \tsplit a multi-sample VCF into one file per sample\n",
      "\tvcfdecompose \tdecompose complex variants within a VCF file\n",
      "\tvcfeval      \tevaluate called variants for agreement with a baseline variant\n",
      "\t             \tset\n",
      "\tsvdecompose  \tsplit composite structural variants into a breakend\n",
      "\t             \trepresentation\n",
      "\tbndeval      \tevaluate called breakends for agreement with a baseline breakend\n",
      "\t             \tset\n",
      "\tpedfilter    \tfilter and convert a pedigree file\n",
      "\tpedstats     \tprint information about a pedigree file\n",
      "\trocplot      \tplot ROC curves from vcfeval ROC data files\n",
      "\tversion      \tprint version and license information\n",
      "\tlicense      \tprint license information for all commands\n",
      "\thelp         \tprint this screen or help for specified command\n"
     ]
    }
   ],
   "source": [
    "run(pipeline(`/opt/rtg/rtg-tools-3.11/rtg`, stdout=pipeline(`no`)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: rtg vcfeval [OPTION]... -b FILE -c FILE -o DIR -t SDF\n",
      "\n",
      "Evaluates called variants for genotype agreement with a baseline variant set\n",
      "irrespective of representational differences. Outputs a weighted ROC file which\n",
      "can be viewed with rtg rocplot and VCF files containing false positives (called\n",
      "variants not matched in the baseline), false negatives (baseline variants not\n",
      "matched in the call set), and true positives (variants that match between the\n",
      "baseline and calls).\n",
      "\n",
      "File Input/Output\n",
      "  -b, --baseline=FILE           VCF file containing baseline variants\n",
      "      --bed-regions=FILE        if set, only read VCF records that overlap the\n",
      "                                ranges contained in the specified BED file\n",
      "  -c, --calls=FILE              VCF file containing called variants\n",
      "  -e, --evaluation-regions=FILE if set, evaluate within regions contained in\n",
      "                                the supplied BED file, allowing transborder\n",
      "                                matches. To be used for truth-set\n",
      "                                high-confidence regions or other regions of\n",
      "                                interest where region boundary effects should\n",
      "                                be minimized\n",
      "  -o, --output=DIR              directory for output\n",
      "      --region=REGION           if set, only read VCF records within the\n",
      "                                specified range. The format is one of\n",
      "                                <sequence_name>, <sequence_name>:<start>-<end>,\n",
      "                                <sequence_name>:<pos>+<length> or\n",
      "                                <sequence_name>:<pos>~<padding>\n",
      "  -t, --template=SDF            SDF of the reference genome the variants are\n",
      "                                called against\n",
      "\n",
      "Filtering\n",
      "      --all-records             use all records regardless of FILTER status\n",
      "                                (Default is to only process records where\n",
      "                                FILTER is \".\" or \"PASS\")\n",
      "      --decompose               decompose complex variants into smaller\n",
      "                                constituents to allow partial credit\n",
      "      --ref-overlap             allow alleles to overlap where bases of either\n",
      "                                allele are same-as-ref (Default is to only\n",
      "                                allow VCF anchor base overlap)\n",
      "      --sample=STRING           the name of the sample to select. Use\n",
      "                                <baseline_sample>,<calls_sample> to select\n",
      "                                different sample names for baseline and calls.\n",
      "                                (Required when using multi-sample VCF files)\n",
      "      --squash-ploidy           treat heterozygous genotypes as homozygous ALT\n",
      "                                in both baseline and calls, to allow matches\n",
      "                                that ignore zygosity differences\n",
      "\n",
      "Reporting\n",
      "      --at-precision=FLOAT      output summary statistics where precision >=\n",
      "                                supplied value (Default is to summarize at\n",
      "                                maximum F-measure)\n",
      "      --at-sensitivity=FLOAT    output summary statistics where sensitivity >=\n",
      "                                supplied value (Default is to summarize at\n",
      "                                maximum F-measure)\n",
      "      --no-roc                  do not produce ROCs\n",
      "  -m, --output-mode=STRING      output reporting mode. Allowed values are\n",
      "                                [split, annotate, combine, ga4gh, roc-only]\n",
      "                                (Default is split)\n",
      "  -O, --sort-order=STRING       the order in which to sort the ROC scores so\n",
      "                                that \"good\" scores come before \"bad\" scores.\n",
      "                                Allowed values are [ascending, descending]\n",
      "                                (Default is descending)\n",
      "  -f, --vcf-score-field=STRING  the name of the VCF FORMAT field to use as the\n",
      "                                ROC score. Also valid are \"QUAL\", \"INFO.<name>\"\n",
      "                                or \"FORMAT.<name>\" to select the named VCF\n",
      "                                FORMAT or INFO field (Default is GQ)\n",
      "\n",
      "Utility\n",
      "  -h, --help                    print help on command-line flag usage\n",
      "  -Z, --no-gzip                 do not gzip the output\n",
      "  -T, --threads=INT             number of threads (Default is the number of\n",
      "                                available cores)\n",
      "\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "failed process: Process(`/opt/rtg/rtg-tools-3.11/rtg vcfeval --help`, ProcessExited(1)) [1]\n",
     "output_type": "error",
     "traceback": [
      "failed process: Process(`/opt/rtg/rtg-tools-3.11/rtg vcfeval --help`, ProcessExited(1)) [1]\n",
      "",
      "Stacktrace:",
      " [1] pipeline_error at ./process.jl:525 [inlined]",
      " [2] run(::Cmd; wait::Bool) at ./process.jl:440",
      " [3] run(::Cmd) at ./process.jl:438",
      " [4] top-level scope at In[8]:1",
      " [5] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "run(pipeline(`/opt/rtg/rtg-tools-3.11/rtg vcfeval --help`))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ispath(benchmark_data_dir)\n",
    "\n",
    "for (root, dirs, files) in walkdir(benchmark_data_dir)\n",
    "    println(\"Directories in $root\")\n",
    "    for dir in dirs\n",
    "        println(joinpath(root, dir)) # path to directories\n",
    "    end\n",
    "    println(\"Files in $root\")\n",
    "    for file in files\n",
    "        println(joinpath(root, file)) # path to files\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.2",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
